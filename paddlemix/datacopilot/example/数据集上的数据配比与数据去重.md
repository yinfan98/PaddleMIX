# 数据集上的数据配比与数据去重

|            |                                |
| ---------- | ------------------------------ |
| 提交作者   | yinfan98(企鹅火烈鸟)                 |
| 提交时间   | 2024-12-23                     |
| RFC 版本号 | v1.0                           |
| 文件名     | 数据集上的数据配比与数据去重.md |

## 1. 概述

### 1.1 相关背景

多模态模型通常需要同时处理文本、图像、语音、视频等多种模态的数据。在构建或清洗数据集时，容易遇到以下问题：

1. 重复样本（Exact Duplicates 或 Near Duplicates）
- 同一文本重复多次
- 同一图像（或极度相似的图像）出现多次
- 文本-图像对中，文本相同但图像相同或近似
- 视频帧截取重复等

2. 配比不均衡（Class/Modal/Label imbalance）
- 某一类别样本量远大于（或远小于）其他类别
- 文本与图像在多模态对中一对多或多对一的情况
- 不同模态之间样本数量严重失衡

### 1.2 功能目标

为解决上述问题，需对数据集执行如下步骤：

- 检测并去除重复样本，减少冗余数据
- 统计并分析不同类别/模态/标签的比例分布，是否存在明显失衡
- 根据业务需求对数据进行抽样或补足，保证整体分布更均衡

### 1.3 意义

本处理pipeline完善了整体处理流程，设计了合理的数据配比。以增强模型的基础能力。

## 2.方案背景

### 2.1 数据处理面临的挑战

1. 重复样本（Duplicate Samples）
- 处于初步数据收集阶段时，可能会多次抓取到相同的文本、图像或其他文件，导致数据集中存在大量“Exact Duplicates”或“Near Duplicates”。这些重复样本往往会导致模型训练时的有效信息冗余，无法帮助模型学到更多新的特征。
- 不同模态之间也可能存在重复现象。例如，同一文本被不同图片重复引用，或相似的图像对应完全相同的文本描述。

2. 数据配比不均衡（Data Imbalance）
- 在多模态语料中，某些类别的样本量明显多于其它类别，或有的标签样本极端稀少，导致模型难以在所有类别上均衡学习。
- 某些模态（如文本-图像对）可能发生样本缺失或匹配异常。例如，同一文本对应多幅图像；或只存在文本却缺乏对应的图像等。

## 3.目标调研

在多模态数据的预处理中，如何高效地“去除重复样本”与“动态分析数据占比”是两个关键目标。为此，本算子需要在功能设计上满足下列需求：

1. 去重算子：
- 能快速、准确地识别并移除多模态数据中的重复目标（例如，文本重复、图像重复或文本-图像对重复），减少数据冗余。
- 针对完全重复与近似重复均能提供检测方式，并可根据阈值或业务需求灵活配置，避免无意中删除有价值的相似数据。

2. 动态配比分析与可视化：
- 根据数据集内的不同类别或标签，自动统计各类别的样本数量或占比情况。
- 以饼图、柱状图等直观方式展示分析结果，让用户能够快速把握数据分布与类别占比；并且可在数据更新后，通过动态刷新或重新运行算子来及时获取最新的配比图表。

## 4.设计思路与实现方案

### 4.1 核心模块设计

在多模态数据处理流程中，去重与可视化分析并非一蹴而就，而是由多个核心模块相互配合、协同完成的。下面列出的各核心模块承担不同的功能职责，彼此之间通过数据流或接口进行交互，从而实现高效的数据去重与动态配比分析。

为了更直观地展示模块拆分及其主要职责，可参考下表：

| 模块名称                                       | 功能概述                                                                                                                                                   | 依赖模块                                         | 备注                                                                      |
|:-------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------|:------------------------------------------------------------------------|
| 重复检测模块 (Duplicate Detection)                | 1. 利用哈希算法、相似度计算等，检测并标记重复/近似重复样本<br>2. 为后续去重/平衡操作提供参考列表                                                                                | 需要从数据预处理模块获取 <br> 规范化后的文本、图像特征               | 可结合SimHash、pHash、dHash或深度特征等多种检测方案                                                |
| 占比统计与可视化模块 (Ratio Analysis & Visualization)   | 1. 统计各类别、各模态的样本分布<br>2. 生成饼图、柱状图等图表，以展示类别占比、模态占比或缺失率                                                                                  | 与重复检测模块联动， <br> 读写去重后的数据统计信息                  | 为后续决策是否执行抽样/增样以及如何调优模型提供可信依据                                                |
| 去重与数据平衡模块 (Data Cleaning & Balancing)        | 1. 根据重复检测结果去除冗余样本<br>2. 对严重失衡的类别进行欠采样或过采样                                                                                               | 需要重复检测的标记信息 <br> 需要可视化模块给出失衡评估           | 该模块需确保数据结构和标签的一致性，以免删除或增样后破坏数据完整性                                         |
| 输出与报告模块 (Output & Reporting)              | 1. 输出最终清洗、平衡后的数据，形成新的数据集<br>2. 记录元数据，包括去重率、各类别数量变化情况，并生成最终报告或日志                                                               | 依赖前面所有模块输出的统计结果                              | 可在此阶段将处理后数据上传到新的存储或交付到后续建模流程                                                 |


---

### 4.2 核心算子设计

在核心模块框架下，具体的技术细节与实现手段往往封装成“算子（Operator）”。算子可理解为完成某一特定功能的可复用组件，如文本重复对比算子、图像哈希算子、配比分析算子等。下面给出去重与动态分析常用的核心算子示例表：

| 算子名称                                  | 输入                                                                 | 输出                                                         | 核心算法 / 处理流程                                                                                                                                                        | 备注                                            |
|:--------------------------------------|:-------------------------------------------------------------------|:-----------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------|
| 文本去重算子 <br>(Text Deduplicate Operator)     | 1. 标准化后的文本序列或文档列表<br>2. 去重阈值（可选）                                         | 重复文本列表 / 标记信息<br>（如重复的行索引），以及去重后的文本数据集         | 1. 精确重复：简单哈希比对或字符串比对<br>2. 近似重复：SimHash / MinHash / 编辑距离等文本相似度计算<br>3. 标注重复样本并可进行剔除操作                                                           | 常用于新闻文本、评论文本等消重场景                         |
| 图像去重算子 <br>(Image Deduplicate Operator)     | 1. 图像路径或已加载图像数据<br>2. 感知哈希阈值（Hamming Distance）                                  | 重复图像列表 / 标记信息<br>（如重复的行索引），以及去重后的图像数据集         | 1. aHash / pHash / dHash 等感知哈希算法<br>2. 比较哈希值的Hamming距离，小于设定阈值则判定为近似重复<br>3. 标注重复样本并可进行剔除操作                                                         | 可对相似图像进行标记以便后续手动检查                        |
| 多模态对去重算子 <br>(Cross-modal Deduplicate)    | 1. 文本-图像（或文本-音频等）配对<br>2. 去重阈值及多模态检测策略                                   | 重复多模态对列表 / 标记信息<br> 以及去重后的多模态数据集               | 1. 分别对各模态做重复检测<br>2. 若同一文本+相似图像经常重复出现，则统一标记<br>3. 根据阈值或策略判断是否需要删除、合并、或保留样本                                                             | 针对多模态任务，让文本与其他模态数据保持一致清洗                      |
| 配比分析算子 <br>(Ratio Analysis Operator)         | 1. 已去重或原始数据集<br>2. 类别/标签信息<br>3. 模态信息（文本、图像）           | 配比统计结果表<br>(如各类占比、模态占比、缺失率)<br>以及可视化图（饼图、柱状图） | 1. 统计各类别/标签/模态占比<br>2. 生成可视化所需数据并调用可视化库（如Matplotlib、Seaborn或Plotly）<br>3. 完成饼图、柱状图等直观可视化输出                                                      | 为决策是否抽样/增样、调优模型提供数据参考                       |
| 抽样/增样算子 <br>(Sampling & Augmentation)        | 1. 去重后数据集<br>2. 配比分析结果<br>3. 抽样或增样策略                                   | 抽样或增样后的平衡数据集                                         | 1. 欠采样（删除多余样本）或过采样（复制、数据增强）<br>2. 图像可做旋转、随机裁剪等增强<br>3. 平衡结果写回数据集并更新Summary                                                                     | 保证数据分布在各类别或模态上更均衡                           |

- 以上算子可根据业务需求灵活组合，形成去重、增样、分析等一整套处理流程。  
- 算子的输入输出可统一定义成特定的数据结构或API接口，在模块之间实现简洁清晰的“流水线”式处理。  
- 对超大型数据集或实时数据流，可以部署分布式算子集群或基于流式计算框架来完成以上功能，提升处理效率。

## 5. 测试和验收的考量

在多模态数据处理中引入“去重”和“数据可视化分析”两个关键功能后，需要通过充分的测试和验收来检验新流程的有效性与稳定性。主要考量点包括：

1. 去重效果与准确性  
   - 在预先标注好的测试集上，对文本重复、图像重复、多模态分别进行检测，看结果是否与人工判断或参考标准一致。  
   - 设置不同的相似度阈值（如文本相似度阈值、图像哈希阈值等），验证其对冗余数据的过滤能力以及对关键数据的保留情况。  
   - 确保误删率（False Positive）与漏删率（False Negative）在可接受范围内，极端场景下（如极度相似图像或文本）也能给出合理判断。

2. 数据可视化与配比分析验证  
   - 检查生成的饼图、柱状图等可视化结果，确认各类别、各模态的样本数量与占比是否与原始统计数据吻合。  
   - 若执行了抽样/增样或去重操作，确认更新后的数据分布能否实时体现在可视化结果中，确保流程闭环。

3. 上下游影响及整体流程稳定性  
   - 在实际业务流程中，使用经过去重并平衡后的数据集训练模型，并于固定测试集上做准确率、召回率等指标对比。若模型性能有所提升且无明显副作用，则表明新的数据清洗方案可行。  
   - 考量数据规模及更新频率，对大批量数据处理场景检查算子的执行效率和容错能力（如断点重试，异常日志记录）。

---

## 6. 可行性分析和排期规划

### 6.1 可行性分析

1. 算法与实现可行性  
   - 文本去重可基于字符串哈希或文本相似度计算（SimHash/MinHash/编辑距离等）实现，图像去重可采用感知哈希（pHash/dHash/aHash）等成熟方法。多模态去重则可结合文本和图像特征的相似度进行综合判定。  
   - 数据配比分析和可视化技术相对成熟，可通过 Python 常用可视化库（Matplotlib、Seaborn、Plotly 等）快速实现。


2. 风险与替代方案  
   - 去重过程若定义阈值不当，会导致有价值数据被误删或无效数据保留；可通过多次迭代调整阈值并进行人工抽查。  
   - 如果数据分布极度失衡或缺失严重，可能需要对抽样/增样模块做分级设计；或在可视化图表中对该情况做突出提示，以便研究者及时介入处理。

### 6.2 排期规划

综合项目规模和各环节实现难度，建议排期如下（约 5 周）：

| 任务                                   | 时间周期 | 说明                                                                                         |
|:-------------------------------------|:-----:|:-------------------------------------------------------------------------------------------|
| 去重方案构建与算子开发 (文本/图像/多模态)       | 2 周   | 1) 选定哈希算法或相似度阈值，并实现去重算子<br>2) 在小规模数据集上完成功能性测试                               |
| 配比统计与可视化算子开发                      | 1 周   | 1) 设计并实现统计与图表生成逻辑<br>2) 固化接口规范，实现与去重流程的数据联动                               |
| 集成测试与性能优化                          | 1 周   | 1) 在真实或较大规模数据环境下进行压力测试<br>2) 优化算子性能并处理潜在异常 (如大批量、极端数据等)                  |
| 上下游衔接与模型效能验证                      | 1 周   | 1) 将去重和可视化算子集成至现有数据处理或训练管线<br>2) 在对比实验中验证新数据对模型精度、规模的影响              |

---

## 7. 影响面

1. 代码结构及模块增量  
   - 在原有项目或数据处理框架内，需要新增多个模块或算子，包括文本去重、图像去重、多模态对去重、占比分析与可视化等，目录结构和依赖关系会相应调整。  

2. 数据处理流程变更  
   - 原有流程若没有去重环节，新增模块可能改变现有模型的训练数据分布，从而影响模型推理效果；需逐步测试并观察数据量、类别比例变化后对业务效果的影响。  
   - 可视化分析后发现数据分布问题，可能需要临时决定执行抽样、增样等操作，以维持数据均衡度；主流程请预留灵活性来支持动态重复检测与增删改操作。
